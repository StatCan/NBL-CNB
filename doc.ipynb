{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "e7c37ba80a6e54a3d63188245ab5de6a3e0d381993bcb1990a7020536fc2299e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Address Points to Polygons\r\n",
    "\r\n",
    "Conversion of address points into building footprints based on proximity and supporting data such as surveyed parcels"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import geopandas as gpd\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import shapely\n",
    "import sys\n",
    "from bisect import bisect\n",
    "from collections import OrderedDict\n",
    "from operator import add, index, itemgetter\n",
    "from shapely import geometry\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], \"..\"))\n",
    "import helpers\n",
    "\n",
    "'''\n",
    "This script is a proof of concept building on the work of Jessie Stewart for the NRN. This script attempts to take\n",
    "building foorprints and match the best address point available to them in order to apply pertinent address fields\n",
    "to the building fooprints.\n",
    "\n",
    "'''\n",
    "\n",
    "# Define Helper Functions\n",
    "def groupby_to_list(df, group_field, list_field):\n",
    "    \"\"\"\n",
    "    Helper function: faster alternative to pandas groupby.apply/agg(list).\n",
    "    Groups records by one or more fields and compiles an output field into a list for each group.\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(group_field, list):\n",
    "        for field in group_field:\n",
    "            if df[field].dtype.name != \"geometry\":\n",
    "                df[field] = df[field].astype(\"U\")\n",
    "        transpose = df.sort_values(group_field)[[*group_field, list_field]].values.T\n",
    "        keys, vals = np.column_stack(transpose[:-1]), transpose[-1]\n",
    "        keys_unique, keys_indexes = np.unique(keys.astype(\"U\") if isinstance(keys, np.object) else keys, \n",
    "                                              axis=0, return_index=True)\n",
    "    \n",
    "    else:\n",
    "        keys, vals = df.sort_values(group_field)[[group_field, list_field]].values.T\n",
    "        keys_unique, keys_indexes = np.unique(keys, return_index=True)\n",
    "    \n",
    "    vals_arrays = np.split(vals, keys_indexes[1:])\n",
    "    \n",
    "    return pd.Series([list(vals_array) for vals_array in vals_arrays], index=keys_unique).copy(deep=True)\n",
    "    \n",
    "\n",
    "output_path = r'H:\\point_to_polygon_PoC'\n",
    "\n",
    "# Layer inputs\n",
    "project_gpkg = \"H:/point_to_polygon_PoC/data/data.gpkg\"\n",
    "addresses_lyr_nme = \"yk_Address_Points\"\n",
    "bf_lyr_nme = \"yk_buildings_sj\"\n",
    "bf_polys = \"yk_buildings_sj\"\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": []
  },
  {
   "source": [
    "Step 0: Read in Data, Data Prep and Cleaning. \n",
    "\n",
    "Read in the data as Geopandas files and then check and clean the data for common issues."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode(ingdf):\n",
    "    # To solve multipolygon issue. Converts Pultipolgons into single Polygons\n",
    "    indf = ingdf\n",
    "    outdf = gpd.GeoDataFrame(columns=indf.columns)\n",
    "    for idx, row in indf.iterrows():\n",
    "        \n",
    "        if type(row.geometry) == Polygon:\n",
    "            outdf = outdf.append(row,ignore_index=True)\n",
    "        if type(row.geometry) == MultiPolygon:\n",
    "            multdf = gpd.GeoDataFrame(columns=indf.columns)\n",
    "            recs = len(row.geometry)\n",
    "            multdf = multdf.append([row]*recs,ignore_index=True)\n",
    "            for geom in range(recs):\n",
    "                multdf.loc[geom,'geometry'] = row.geometry[geom]\n",
    "            outdf = outdf.append(multdf,ignore_index=True)\n",
    "    return outdf\n",
    "\n",
    "    \n",
    "# Load dataframes.\n",
    "addresses = gpd.read_file(project_gpkg, layer= addresses_lyr_nme, crs=26911)\n",
    "footprint = gpd.read_file(project_gpkg, layer= bf_lyr_nme, crs=26911) # spatial join between the parcels and building footprints layers\n",
    "\n",
    "print('Running Step 0. Clean Data')\n",
    "# Clean data\n",
    "# Remove rite of way from the address data and join count > 0\n",
    "addresses = addresses[(addresses.CIVIC_ADDRESS != \"RITE OF WAY\")]\n",
    "\n",
    "# Remove null street name rows\n",
    "footprint = footprint[(footprint.Join_Count > 0) & (footprint.STREET_NAME.notnull()) & (footprint.STREET_NAME != ' ')] \n",
    "\n",
    "footprint = explode(footprint) # Removes any multipolygon features and returns simple polygons\n"
   ]
  },
  {
   "source": [
    "Step 1: Load dataframes and configure attributes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define join fields.\n",
    "join_footprint = \"STREET_NAME\"\n",
    "join_addresses = \"STREET_NAME\"\n",
    "\n",
    "# Configure attributes - number and suffix.\n",
    "addresses[\"suffix\"] = addresses[\"CIVIC_ADDRESS\"].map(lambda val: re.sub(pattern=\"\\\\d+\", repl=\"\", string=val, flags=re.I))\n",
    "addresses[\"number\"] = addresses[\"CIVIC_ADDRESS\"].map(lambda val: re.sub(pattern=\"[^\\\\d]\", repl=\"\", string=val, flags=re.I)).map(int)\n"
   ]
  },
  {
   "source": [
    "Step 2: Configure Address to Footprint Linkages"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_linkage(pt, footprint_indexes):\n",
    "    \"\"\"Returns the footprint index associated with the nearest footprint geometry to the given address point.\"\"\"\n",
    "    pt_geoseries = gpd.GeoSeries([pt])\n",
    "    # Get footprint geometries.\n",
    "    footprint_geometries = tuple(map(lambda index: footprint[\"geometry\"].loc[footprint.index == index], footprint_indexes))\n",
    "    # Get footprint distances from address point.\n",
    "    footprint_distances = tuple(map(lambda building: pt.distance(Point(building.centroid.x, building.centroid.y)), footprint_geometries))                                      \n",
    "    # Get the footprint index associated with the smallest distance.\n",
    "    footprint_index = footprint_indexes[footprint_distances.index(min(footprint_distances))]\n",
    "    return footprint_index\n",
    "\n",
    "\n",
    "# Link addresses and footprint on join fields.\n",
    "addresses[\"addresses_index\"] = addresses.index\n",
    "footprint[\"footprint_index\"] = footprint.index\n",
    "\n",
    "merge = addresses.merge(footprint[[join_footprint, \"footprint_index\"]], how=\"left\", left_on=join_addresses, right_on=join_footprint)\n",
    "addresses[\"footprint_index\"] = groupby_to_list(merge, \"addresses_index\", \"footprint_index\")\n",
    "\n",
    "addresses.drop(columns=[\"addresses_index\"], inplace=True)\n",
    "footprint.drop(columns=[\"footprint_index\"], inplace=True)\n",
    "\n",
    "# Discard non-linked addresses.\n",
    "addresses.drop(addresses[addresses[\"footprint_index\"].map(itemgetter(0)).isna()].index, axis=0, inplace=True)\n",
    "\n",
    "# Convert linkages to integer tuples, if possible.\n",
    "\n",
    "addresses[\"footprint_index\"] = addresses[\"footprint_index\"].map(lambda vals: tuple(set(map(as_int, vals))))\n",
    "\n",
    "# Flag plural linkages.\n",
    "flag_plural = addresses[\"footprint_index\"].map(len) > 1\n",
    "# Reduce plural linkages to the building segment with the lowest (nearest) geometric distance.\n",
    "addresses.loc[flag_plural, \"footprint_index\"] = addresses[flag_plural][[\"geometry\", \"footprint_index\"]].apply(\n",
    "    lambda row: get_nearest_linkage(*row), axis=1)\n",
    "\n",
    "# Unpack first tuple element for singular linkages.\n",
    "addresses.loc[~flag_plural, \"footprint_index\"] = addresses[~flag_plural][\"footprint_index\"].map(itemgetter(0))\n",
    "\n",
    "# Compile linked footprint geometry for each address.\n",
    "addresses[\"footprint_geometry\"] = addresses.merge(\n",
    "    footprint[\"geometry\"], how=\"left\", left_on=\"footprint_index\", right_index=True)[\"geometry_y\"]"
   ]
  },
  {
   "source": [
    "Step 3: Convert Results to Polygons"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_gdf = gpd.GeoDataFrame(addresses, geometry='footprint_geometry', crs=26911)\n",
    "out_gdf.drop(columns='geometry', inplace=True)\n",
    "out_gdf.to_file(os.path.join(output_path, 'addresses_poly.shp'), driver='ESRI Shapefile')"
   ]
  }
 ]
}
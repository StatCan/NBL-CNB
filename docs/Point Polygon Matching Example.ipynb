{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a91235e",
   "metadata": {},
   "source": [
    "## Point Polygon Matching Process Example\n",
    "\n",
    "This notebook gives an example of how the matching script matches the address points to the building footprints. Visualization code blocks are for example purposes only and are not part of the script itself. See matching_master.py for the script in its working format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "659427e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geoplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeoplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstring\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'geoplot'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import geoplot as gplt\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import fiona\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from numpy.core.numeric import True_\n",
    "from operator import add, index, itemgetter\n",
    "sys.path.insert(1, os.path.join(sys.path[0], \"..\"))\n",
    "import pandas as pd\n",
    "from pyproj import crs\n",
    "from shapely import geometry\n",
    "from shapely.geometry import MultiPolygon, Point, Polygon, geo\n",
    "from dotenv import load_dotenv\n",
    "import datetime\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0a0aa2",
   "metadata": {},
   "source": [
    "#### Load in key variables from environments file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef062fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(os.path.join(r'C:\\projects\\point_in_polygon\\scripts', 'NB_environments.env'))\n",
    "\n",
    "output_path = os.getcwd()\n",
    "output_gpkg = Path(os.getenv('MATCHED_OUTPUT_GPKG'))\n",
    "matched_lyr_nme = os.getenv('MATCHED_OUTPUT_LYR_NME')\n",
    "unmatched_lyr_nme = os.getenv('UNMATCHED_OUTPUT_LYR_NME')\n",
    "unmatched_poly_lyr_nme = os.getenv('UNMATCHED_POLY_LYR_NME')\n",
    "\n",
    "# Layer inputs cleaned versions only\n",
    "project_gpkg = Path(os.getenv('DATA_GPKG'))\n",
    "footprints_lyr_nme = os.getenv('CLEANED_BF_LYR_NAME')\n",
    "addresses_lyr_nme = os.getenv('FLAGGED_AP_LYR_NME')\n",
    "\n",
    "proj_crs = int(os.getenv('PROJ_CRS'))\n",
    "\n",
    "add_num_fld_nme =  os.getenv('AP_CIVIC_ADDRESS_FIELD_NAME')\n",
    "unlinked_bf_lyr_nme = os.getenv('UNLINKED_BF_LYR_NME')\n",
    "\n",
    "out_lyr_nme = os.getenv('LINKED_BY_DATA_NME')\n",
    "\n",
    "buffer_size = 20 # distance for the buffer\n",
    "\n",
    "metrics_out_path = Path(os.getenv('METRICS_CSV_OUT_PATH'))\n",
    "\n",
    "bp_threshold = int(os.getenv('BP_THRESHOLD'))\n",
    "bp_area_threshold = int(os.getenv('BP_AREA_THRESHOLD'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b91610",
   "metadata": {},
   "source": [
    "#### Step 1. Load in data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efc634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_aoi = gpd.read_file(r'C:\\projects\\point_in_polygon\\data\\NB_data\\vis_aoi.shp')\n",
    "vis_aoi.to_crs(crs=4326, inplace=True)\n",
    "extent = vis_aoi.total_bounds\n",
    "addresses = gpd.read_file(project_gpkg, layer=addresses_lyr_nme, crs=proj_crs)\n",
    "addresses.to_crs(crs= proj_crs, inplace=True)\n",
    "\n",
    "print(addresses[['link_field', 'parcel_rel', 'geometry']].head())\n",
    "\n",
    "gplt.pointplot(addresses.to_crs(crs=4326), extent=extent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced157da",
   "metadata": {},
   "outputs": [],
   "source": [
    "footprint = gpd.read_file(project_gpkg, layer=footprints_lyr_nme, crs=proj_crs)\n",
    "footprint.to_crs(crs=proj_crs, inplace=True)\n",
    "\n",
    "print(footprint[['link_field','geometry']].head())\n",
    "gplt.polyplot(footprint.to_crs(crs=4326), extent=extent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8bd930",
   "metadata": {},
   "source": [
    "#### Step 2. Configure address to building polygon linkage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e54ca9",
   "metadata": {},
   "source": [
    "In the next step the goal is to determine the linkage between the address point and building polygon. This is done by using several methods. First, a list is created of all building polygons that match the link_field value of each given address point. This is compiled as a list in the addresses dataframe as the field footprint_index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646aa19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupby_to_list(df, group_field, list_field):\n",
    "    \n",
    "    \"\"\"\n",
    "    Helper function: faster alternative to pandas groupby.apply/agg(list).\n",
    "    Groups records by one or more fields and compiles an output field into a list for each group.\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(group_field, list):\n",
    "        for field in group_field:\n",
    "            if df[field].dtype.name != \"geometry\":\n",
    "                df[field] = df[field].astype(\"U\")\n",
    "        transpose = df.sort_values(group_field)[[*group_field, list_field]].values.T\n",
    "        keys, vals = np.column_stack(transpose[:-1]), transpose[-1]\n",
    "        keys_unique, keys_indexes = np.unique(keys.astype(\"U\") if isinstance(keys, np.object) else keys, \n",
    "                                              axis=0, return_index=True)\n",
    "    \n",
    "    else:\n",
    "        keys, vals = df.sort_values(group_field)[[group_field, list_field]].values.T\n",
    "        keys_unique, keys_indexes = np.unique(keys, return_index=True)\n",
    "    \n",
    "    vals_arrays = np.split(vals, keys_indexes[1:])\n",
    "    \n",
    "    return pd.Series([list(vals_array) for vals_array in vals_arrays], index=keys_unique).copy(deep=True)\n",
    "\n",
    "# Define join fields.\n",
    "join_footprint = 'link_field'\n",
    "join_addresses = 'link_field'\n",
    "\n",
    "\n",
    "# Link addresses and footprint on join fields.\n",
    "\n",
    "addresses[\"addresses_index\"] = addresses.index\n",
    "footprint[\"footprint_index\"] = footprint.index\n",
    "\n",
    "# Remove buildings flagged as sheds as they do not need to be matched\n",
    "footprint = footprint[footprint['shed_flag'] == False]\n",
    "\n",
    "merge = addresses[~addresses[join_addresses].isna()].merge(footprint[[join_footprint, \"footprint_index\"]], how=\"left\", left_on=join_addresses, right_on=join_footprint)\n",
    "\n",
    "addresses['footprint_index'] = groupby_to_list(merge, \"addresses_index\", \"footprint_index\")\n",
    "addresses.drop(columns=[\"addresses_index\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cc3491",
   "metadata": {},
   "source": [
    "A sample of the results of the above process can be seen printed out below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bbfe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(addresses['footprint_index'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092c881b",
   "metadata": {},
   "source": [
    "There are cases where there are lots of small buildings on a parcel each containing a single address. Examples of this are trailer parks and Indigenous Reserves the nature of the data in these areas is such that using data linking is not the most accurate method of creating a match. In these cases we utilize the 'big parcel' method where these parcels are isolated and a proximity buffer is used for each point to create a single match. The records are filtered out from the main addresses dataset as they have been matched.\n",
    "\n",
    "Below are the key functions for making this process work: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e182d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def building_area_theshold_id(building_gdf, bf_area_threshold , area_field_name='bf_area'):\n",
    "    '''\n",
    "    Returns a boolean on whether a majority of the buildings in the bp fall under the bp threshold defined in the environments. \n",
    "    Buildings should be filtered to only those in the polygon before being passed into this function\n",
    "    '''\n",
    "    \n",
    "    all_bf_cnt = len(building_gdf)\n",
    "\n",
    "    bf_u_thresh = building_gdf[building_gdf[area_field_name] <= bf_area_threshold]\n",
    "    bf_u_thresh_cnt = len(bf_u_thresh)\n",
    "\n",
    "    if bf_u_thresh_cnt >= (all_bf_cnt/2):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "\n",
    "def get_unlinked_geometry(addresses_gdf, footprint_gdf , buffer_distance:int):\n",
    "    'Returns indexes for the bf based on the increasing buffer size'\n",
    "    \n",
    "    def list_bf_indexes(buffer_geom, bf_gdf):\n",
    "        \"\"\"\n",
    "        For parcel-less bf geometry takes the buffer from the buffer_geom field and looks for \n",
    "        intersects based on the buffer geom. Returns a list of all indexes with true values.\n",
    "        \"\"\"\n",
    "        intersects = bf_gdf.intersects(buffer_geom)\n",
    "        intersects = intersects[intersects == True]\n",
    "        intersects = tuple(intersects.index)\n",
    "        if len(intersects) > 0:\n",
    "            return intersects\n",
    "        else: \n",
    "            return np.nan\n",
    "    \n",
    "    addresses_gdf['buffer_geom'] = addresses_gdf.geometry.buffer(buffer_distance)\n",
    "    addresses_gdf[f'footprint_index'] = addresses_gdf['buffer_geom'].apply(lambda point_buffer: list_bf_indexes(point_buffer, footprint_gdf))\n",
    "\n",
    "    linked_df = addresses_gdf.dropna(axis=0, subset=[f'footprint_index'])\n",
    "    linked_df['method'] = f'{buffer_distance}m buffer'\n",
    "    linked_df.drop(columns=[\"buffer_geom\"], inplace=True)\n",
    "    addresses_gdf = addresses_gdf[~addresses_gdf.index.isin(list(set(linked_df.index.tolist())))]\n",
    "    return linked_df\n",
    "\n",
    "\n",
    "def get_nearest_linkage(ap, footprint_indexes):\n",
    "    \"\"\"Returns the footprint index associated with the nearest footprint geometry to the given address point.\"\"\"  \n",
    "    # Get footprint geometries.\n",
    "    footprint_geometries = tuple(map(lambda index: footprint[\"geometry\"].loc[footprint.index == index], footprint_indexes))\n",
    "    # Get footprint distances from address point.\n",
    "    footprint_distances = tuple(map(lambda footprint: footprint.distance(ap), footprint_geometries))                                     \n",
    "    distance_values = [a[a.index == a.index[0]].values[0] for a in footprint_distances if len(a.index) != 0]\n",
    "    distance_indexes = [a.index[0] for a in footprint_distances if len(a.index) != 0]\n",
    "\n",
    "    if len(distance_indexes) == 0: # If empty then return drop val\n",
    "        return np.nan\n",
    "\n",
    "    footprint_index =  distance_indexes[distance_values.index(min(distance_values))]\n",
    "    return footprint_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea11735",
   "metadata": {},
   "source": [
    "In the step below the following actions occur. First a count is created for all building polygons and address points by link_id. This gives a count of how many address points and building polygons are in a given parcel. This number is then compared against the bp_threshold. The bp_threshold is the number of ojects of each type that must be present in order to meet the criteria to go through the bp process. \n",
    "\n",
    "Next for any records that meet the bp criteria another check is performed. This checks to see if the majority of buildings   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b000922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big Parcel (BP) case extraction (remove and match before all other cases)\n",
    "bf_counts = footprint.groupby('link_field', dropna=True)['link_field'].count()\n",
    "ap_counts = addresses.groupby('link_field', dropna=True)['link_field'].count()\n",
    "# Take only parcels that have more than the big parcel (bp) threshold intersects of both a the inputs\n",
    "addresses_bp = addresses.loc[(addresses['link_field'].isin(bf_counts[bf_counts > bp_threshold].index.tolist())) & (addresses['link_field'].isin(ap_counts[ap_counts > bp_threshold].index.tolist()))]\n",
    "\n",
    "if len(addresses_bp) > 0:\n",
    "    # return all addresses with a majority of the buildings under the area threshold\n",
    "    addresses_bp['u_areaflag'] = addresses_bp['footprint_index'].apply(lambda x: building_area_theshold_id(footprint[footprint['footprint_index'].isin(x)], bp_area_threshold)) \n",
    "    addresses_bp = addresses_bp.loc[addresses_bp['u_areaflag'] == True]\n",
    "    addresses_bp.drop(columns=['u_areaflag'], inplace=True)\n",
    "\n",
    "    addresses =  addresses[~addresses.index.isin(addresses_bp.index.tolist())]\n",
    "    addresses_bp = get_unlinked_geometry(addresses_bp, footprint, buffer_distance=buffer_size)\n",
    "\n",
    "    # Find and reduce plural linkages to the closest linkage\n",
    "    ap_bp_plural = addresses_bp['footprint_index'].map(len) > 1\n",
    "    addresses_bp.loc[ap_bp_plural, \"footprint_index\"] = addresses_bp[ap_bp_plural][[\"geometry\", \"footprint_index\"]].apply(lambda row: get_nearest_linkage(*row), axis=1)\n",
    "    addresses_bp.loc[~ap_bp_plural, \"footprint_index\"] = addresses_bp[~ap_bp_plural][\"footprint_index\"].map(itemgetter(0))\n",
    "    addresses_bp['method'] = addresses_bp['method'].astype(str) + '_bp'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547fafb0",
   "metadata": {},
   "source": [
    "Now we return to configuring the linkages on the remainder of the records. Some addresses do not fall within a parcel and do not have a parcel linkage. These are separated out and checked using a proximity buffer method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef96c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract non-linked addresses if any.\n",
    "addresses_na = addresses[addresses['footprint_index'].isna()] # Special cases with NaN instead of a tuple\n",
    "addresses = addresses[~addresses.index.isin(addresses_na.index.tolist())]\n",
    "\n",
    "unlinked_aps = addresses[addresses[\"footprint_index\"].map(itemgetter(0)).isna()] # Extract unlinked addresses\n",
    "if len(addresses_na) > 0:    \n",
    "    unlinked_aps = unlinked_aps.append(addresses_na) # append unlinked addresses to the addresses_na\n",
    "\n",
    "# Separate out for the buffer phase\n",
    "addresses.drop(addresses[addresses[\"footprint_index\"].map(itemgetter(0)).isna()].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dc9469",
   "metadata": {},
   "source": [
    "#### Step 3. Checking address linkages via intersects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42443dae",
   "metadata": {},
   "source": [
    "In this step the first set of matches are made on the address dataset as a whole. The first method used is whether the point directly intersects the building polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba294b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_intersects(address_pt, footprint_indexes):\n",
    "    '''Similar to the get nearest linkage function except this looks for intersects (uses within because its much faster) and spits out the index of any intersect'''\n",
    "    footprint_geometries = tuple(map(lambda index: footprint[\"geometry\"].loc[footprint.index == index], footprint_indexes))\n",
    "    inter = tuple(map(lambda bf: address_pt.within(bf.iloc[0]), footprint_geometries))\n",
    "    if True in inter:\n",
    "        t_index = inter.index(True)\n",
    "        return int(footprint_geometries[t_index].index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7352f6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses['intersect_index'] = addresses[[\"geometry\", \"footprint_index\"]].apply(lambda row: check_for_intersects(*row), axis=1)\n",
    "# Clean footprints remove none values and make sure that the indexes are integers\n",
    "intersections = addresses.dropna(axis=0, subset=['intersect_index'])\n",
    "\n",
    "addresses = addresses[addresses.intersect_index.isna()] # Keep only address points that were not intersects\n",
    "addresses.drop(columns=['intersect_index'], inplace=True) # Now drop the now useless intersects_index column\n",
    "\n",
    "intersect_a_points = list(set(intersections.intersect_index.tolist()))\n",
    "\n",
    "addresses.dropna(axis=0, subset=['footprint_index'], inplace=True)\n",
    "\n",
    "intersections['intersect_index'] = intersections['intersect_index'].astype(int)\n",
    "\n",
    "intersect_indexes = list(set(intersections.index.tolist()))\n",
    "\n",
    "intersections['footprint_index'] = intersections['intersect_index']\n",
    "intersections.drop(columns='intersect_index', inplace=True)\n",
    "intersections['method'] = 'intersect'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04fff82",
   "metadata": {},
   "source": [
    "#### Step 4. Create Address Linkages Using Linking Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c9201c",
   "metadata": {},
   "source": [
    "In the code block below all plural linkages from the data linking method are exploded so that each linkage gets its own unique row. This creates a linkage for every building in the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff4359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_int(val):\n",
    "    \"Step 4: Converts linkages to integer tuples, if possible\"\n",
    "    try:\n",
    "        if isinstance(val, int):\n",
    "            return val\n",
    "        else:\n",
    "            return int(val)\n",
    "    except ValueError:\n",
    "        return val\n",
    "\n",
    "# Convert linkages to integer tuples, if possible.\n",
    "addresses[\"footprint_index\"] = addresses[\"footprint_index\"].map(lambda vals: tuple(set(map(as_int, vals))))\n",
    "\n",
    "# Flag plural linkages.\n",
    "flag_plural = addresses[\"footprint_index\"].map(len) > 1\n",
    "addresses = addresses.explode('footprint_index') # Convert the lists into unique rows per building linkage (cleaned up later)\n",
    "\n",
    "addresses = addresses[addresses['footprint_index'] != np.nan]\n",
    "addresses['method'] = 'data_linking'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5083aec",
   "metadata": {},
   "source": [
    "Next all buildings that did not recieve a linkage in the previous steps are now put through a process where a linkage is attempted to be created through the use of a buffer. As with the big parcel step in cases where the linkage is plural the closest building to the addresses point is taken as the match. Two different methods are used at this stage:\n",
    "\n",
    "1.) If an address point does not fall in a parcel it is only compared aginst buildings that have yet to recieve a match.\n",
    "2.) If an address point falls within a parcel it is compared against all buildings regardless of other matches\n",
    "\n",
    "This difference in method used is due to certain types of buildings crossing parcel boundaries and having valid addresses in both parcels (ex. semi detached houses). Address points that fall outside of a parcel are more often then not, unrelated to nearby buildings already linked to an address point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e161a2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(unlinked_aps) > 0:\n",
    "    \n",
    "    unlinked_aps.to_crs(proj_crs, inplace=True)\n",
    "    unlinked_aps.drop(columns=['footprint_index'], inplace=True)\n",
    "\n",
    "    # split into two groups = points linked to a parcel - run against full building dataset, points with no footprint - only run against unlinked buildings\n",
    "    no_parcel = unlinked_aps[unlinked_aps['link_field'].isna()]\n",
    "    parcel_link = unlinked_aps[~unlinked_aps['link_field'].isna()]\n",
    "\n",
    "    # get all footprint_indexes (fi) from the previous steps to exclude in the next step for no parcel aps\n",
    "    intersect_fi = list(set(intersections.footprint_index.tolist()))\n",
    "    linking_fi = list(set(addresses.footprint_index.tolist()))\n",
    "\n",
    "    # Bring in only those footprints that haven't yet been matched to remove matches on buildings already matched\n",
    "    unlinked_footprint = footprint[~(footprint['footprint_index'].isin(linking_fi) | footprint['footprint_index'].isin(intersect_fi))]\n",
    "\n",
    "    # run the next line using only the footprints that are not already linked to an address point\n",
    "    no_parcel = get_unlinked_geometry(no_parcel, unlinked_footprint, buffer_size)\n",
    "    parcel_link = get_unlinked_geometry(parcel_link, footprint, buffer_size)\n",
    "    \n",
    "    # Grab those records that still have no link and export them for other analysis\n",
    "    unmatched_points = unlinked_aps[~((unlinked_aps.index.isin(list(set(no_parcel.index.to_list())))) | (unlinked_aps.index.isin(list(set(parcel_link.index.to_list())))))]\n",
    "    \n",
    "    unlinked_aps = no_parcel.append(parcel_link)\n",
    "    # Take only the closest linkage for unlinked geometries\n",
    "    unlinked_plural = unlinked_aps['footprint_index'].map(len) > 1\n",
    "    unlinked_aps.loc[unlinked_plural, \"footprint_index\"] = unlinked_aps[unlinked_plural][[\"geometry\", \"footprint_index\"]].apply(lambda row: get_nearest_linkage(*row), axis=1)\n",
    "    unlinked_aps = unlinked_aps.explode('footprint_index')\n",
    "    unlinked_aps['method'] = f'{buffer_size}m_buffer'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1747ba",
   "metadata": {},
   "source": [
    "#### Step 5. Merge and Export Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a88c28",
   "metadata": {},
   "source": [
    "All possible matches have now been made. In the step below all matched records are merged into a single dataset and exported for manual review. All data that could not be linked for one reason or another is also exported into their own layers for review via other processes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3485c4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_centroid_match(footprint_index, bf_centroids):\n",
    "    '''Returns the centroid geometry for a given point'''\n",
    "    new_geom = bf_centroids.iloc[int(footprint_index)]\n",
    "    return new_geom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c770e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "outgdf = addresses.append([intersections, addresses_bp, unlinked_aps])\n",
    "\n",
    "# Create representitive points for the building polygons\n",
    "footprint['centroid_geo'] = footprint['geometry'].apply(lambda bf: bf.representative_point())\n",
    "print('     Matching address points with footprint centroids')\n",
    "outgdf['out_geom'] = outgdf['footprint_index'].apply(lambda row: create_centroid_match(row, footprint['centroid_geo']))\n",
    "\n",
    "outgdf = outgdf.set_geometry('out_geom')\n",
    "\n",
    "outgdf.drop(columns='geometry', inplace=True)\n",
    "outgdf.rename(columns={'out_geom':'geometry'}, inplace=True)\n",
    "outgdf = outgdf.set_geometry('geometry')\n",
    "\n",
    "footprint.drop(columns='centroid_geo', inplace=True)\n",
    "\n",
    "# Find unlinked building polygons\n",
    "unlinked_footprint = footprint[~footprint['footprint_index'].isin(outgdf['footprint_index'].to_list())]\n",
    "\n",
    "# Export unlinked building polygons\n",
    "unlinked_footprint.to_file(output_gpkg, layer=unmatched_poly_lyr_nme, driver='GPKG')\n",
    "\n",
    "# Export matched address geometry\n",
    "outgdf.to_file(output_gpkg, layer=matched_lyr_nme,  driver='GPKG')\n",
    "# Export unmatched address geometry\n",
    "unmatched_points.to_file(output_gpkg, layer=unmatched_lyr_nme, driver='GPKG')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

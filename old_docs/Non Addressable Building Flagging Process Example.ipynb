{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a58d03b",
   "metadata": {},
   "source": [
    "# Non Addressable Building Flagging Process Example\n",
    "\n",
    "### Introduction\n",
    "\n",
    "One key component of the data cleaning process is the identification of non addressable outbuildings (NAO). A NAO is any building that should not be matched with an address as it is not considered addressable. Some examples of what are considered to be NAOs include (but are not limited to): garages, gazebos, water towers, and maintenance sheds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b75386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import fiona\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import swifter\n",
    "from dotenv import load_dotenv\n",
    "from numpy.core.numeric import True_\n",
    "from pyproj import crs\n",
    "from shapely import geometry\n",
    "from shapely.geometry import MultiPolygon, Point, Polygon, geo\n",
    "from math import pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53917410",
   "metadata": {},
   "source": [
    "### Inputs\n",
    "\n",
    "There are several datasets that are key in identifying NAOs. The base three layers are required for this process to function (address points, building footprints, cadastral parcels).\n",
    "\n",
    "In the cell below the key layers are loaded in the address points and the cadastral data are the cleaned versions as during the cleaning script they are cleaned first. On the footprints basic cleaning and link is done so that they are ready for the shed flagging process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b08e1efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and prepping footprint data\n"
     ]
    }
   ],
   "source": [
    "def reproject(ingdf, output_crs):\n",
    "    ''' Takes a gdf and tests to see if it is in the projects crs if it is not the funtions will reproject '''\n",
    "    if ingdf.crs == None:\n",
    "        ingdf.set_crs(epsg=output_crs, inplace=True)    \n",
    "    elif ingdf.crs != f'epsg:{output_crs}':\n",
    "        ingdf.to_crs(epsg=output_crs, inplace=True)\n",
    "    return ingdf\n",
    "\n",
    "def return_smallest_match(ap_matches, parcel_df, unique_id):\n",
    "    '''Takes plural matches of buildings or address points and compares them against the size of the matched parcel. Returns only the smallest parcel that was matched'''\n",
    "    ap_matches['ap_match_id'] = range(1, len(ap_matches.index)+1)\n",
    "    o_ids = []\n",
    "    for rid in list(set(ap_matches[unique_id].tolist())):\n",
    "        rid_matches = ap_matches[ap_matches[unique_id] == rid]\n",
    "        rid_ids = list(set(rid_matches['link_field'].tolist()))\n",
    "        match_parcels = parcel_df[parcel_df['link_field'].isin(rid_ids)]\n",
    "        match_parcels.sort_values(by=['AREA'], inplace=True, ascending=True)\n",
    "        min_parcel_link = match_parcels['link_field'].tolist()[0]\n",
    "        o_ids.append(rid_matches[rid_matches['link_field'] == min_parcel_link].ap_match_id.tolist()[0])\n",
    "    ap_matches = ap_matches[ap_matches['ap_match_id'].isin(o_ids)]\n",
    "    ap_matches.drop(columns=['ap_match_id'], inplace=True)\n",
    "    return ap_matches\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "load_dotenv(os.path.join(r'C:\\projects\\point_in_polygon\\scripts', 'NB_environments.env'))\n",
    "\n",
    "proj_crs = os.getenv('PROJ_CRS')\n",
    "aoi_mask = os.getenv('AOI_MASK')\n",
    "aoi_gdf = None\n",
    "if aoi_mask != None:\n",
    "    aoi_gdf = gpd.read_file(aoi_mask)\n",
    "\n",
    "footprint_lyr = Path(os.getenv('BF_PATH'))\n",
    "footprint_lyr_name = os.getenv('BF_LYR_NME')\n",
    "\n",
    "project_gpkg = Path(os.getenv('DATA_GPKG'))\n",
    "\n",
    "linking_data = gpd.read_file(project_gpkg, layer='parcels_cleaned', driver='GPKG')\n",
    "addresses = gpd.read_file(project_gpkg, layer='addresses_cleaned', driver='GPKG')\n",
    "\n",
    "footprint = gpd.read_file(footprint_lyr, layer=footprint_lyr_name ,mask=aoi_gdf)\n",
    "\n",
    "footprint = reproject(footprint, proj_crs)\n",
    "\n",
    "footprint['geometry'] = footprint['geometry'].buffer(0)\n",
    "\n",
    "print('Cleaning and prepping footprint data')\n",
    "# footprint = explode(footprint) # Remove multipart polygons convert to single polygons\n",
    "footprint['bf_area'] = footprint['geometry'].area\n",
    "# footprint = footprint.loc[footprint.area >= 20.0] # Remove all buildings with an area of less than 20m**2\n",
    "footprint = footprint.reset_index()\n",
    "footprint.rename(columns={'index':'bf_index'}, inplace=True)\n",
    "footprint.set_index(footprint['bf_index'])\n",
    "footprint = reproject(footprint, proj_crs)\n",
    "\n",
    "footprint['centroid_geo'] = footprint['geometry'].swifter.apply(lambda pt: pt.centroid)\n",
    "footprint = footprint.set_geometry('centroid_geo')\n",
    "footprint = gpd.sjoin(footprint, linking_data[['link_field', 'geometry']], how='left', op='within')\n",
    "grouped_bf = footprint.groupby('bf_index', dropna=True)['bf_index'].count()\n",
    "grouped_bf = grouped_bf[grouped_bf > 1].index.tolist()\n",
    "footprint_plural_sj = footprint[footprint['bf_index'].isin(grouped_bf)]\n",
    "footprint_singular = footprint[~footprint['bf_index'].isin(grouped_bf)]\n",
    "footprint_plural_sj = return_smallest_match(footprint_plural_sj, linking_data, 'bf_index')\n",
    "footprint = footprint_singular.append(footprint_plural_sj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddb0c30",
   "metadata": {},
   "source": [
    "Below is the function that determines whether or not a building is a non-addressable outbuilding there are a few different processes contianed within that look at different criteria tha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb66c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shed_flagging(footprint_gdf, address_gdf, linking_gdf):\n",
    "    '''\n",
    "    Methodology for finding and flagging buildings as non-addressable outbuildings.\n",
    "    '''\n",
    "    \n",
    "    def find_sheds( bf_data, ap_count, bf_area_field='bf_area', bf_index_field='bf_index', bp_threshold=20, min_adressable_area=50, max_shed_size=100):\n",
    "        '''\n",
    "        returns a list of all bf_indexes that should be flagged as NAOs\n",
    "        and should be considered unaddressable.\n",
    "        take the difference from the counts of each type of record in the parcel and flag the number of smallest\n",
    "        buildings that coorespond with the difference value\n",
    "        '''\n",
    "        bf_count = len(bf_data)\n",
    "        \n",
    "        # If either is equal to zero this method will not help select out sheds\n",
    "        if ap_count == 0 or bf_count == 0:\n",
    "            return []\n",
    "        if bf_count == 1:\n",
    "            return []\n",
    "\n",
    "        # Sizing is different in trailer parks so deal with these differently\n",
    "        if bf_count > bp_threshold:\n",
    "            # do just the tiny building check as the min max between home and shed in these areas overlaps\n",
    "            sheds = bf_data.loc[bf_data[bf_area_field] < min_adressable_area]\n",
    "            shed_indexes = sheds[bf_index_field].values.tolist() # convert to list of indexes\n",
    "            return shed_indexes\n",
    "\n",
    "        # Take out the tiny buildings under 50m2 and prelabel them as sheds then take remainder and test count vs count\n",
    "        sheds = pd.DataFrame(bf_data.loc[bf_data[bf_area_field] < min_adressable_area])\n",
    "        bf_data = bf_data.loc[(bf_data[bf_area_field] > min_adressable_area)]\n",
    "\n",
    "        bf_count = len(bf_data) # reset bf_count because we changed the # of buildings in bf_data\n",
    "\n",
    "        ap_bf_diff = bf_count - ap_count # how many more bf's there are than address points in the parcel\n",
    "        sheds = pd.concat([sheds, bf_data.sort_values(bf_area_field, ascending=True).head(ap_bf_diff)], axis=0, join='outer') # sort the smallest to the top then take the top x rows based on ap_bf_diff value \n",
    "        \n",
    "        sheds = sheds[sheds[bf_area_field] <= max_shed_size] # remove things from the output that are unlikly to be sheds >= 100m2\n",
    "\n",
    "        shed_indexes = sheds[bf_index_field].values.tolist() # convert to list of indexes\n",
    "        return shed_indexes\n",
    "\n",
    "    # Start by finding all the perfectly round buildings and labelling them as sheds size doesn't matter here.\n",
    "    footprint_gdf['perimiter'] = footprint_gdf['geometry'].apply(lambda x: x.length)\n",
    "    footprint_gdf['C'] = footprint_gdf.apply(lambda c: (4*pi*c['bf_area'])/(c['perimiter']*c['perimiter']), axis=1)\n",
    "    # separate out the round sheds from rest of the \n",
    "    round_sheds = footprint_gdf[footprint_gdf['C'] >= 0.98]\n",
    "    footprint_gdf = footprint_gdf[footprint_gdf['C'] < 0.98]\n",
    "    footprint_gdf.drop(columns=['C'], inplace=True)\n",
    "    round_sheds.drop(columns=['C'], inplace=True)\n",
    "    \n",
    "    # Of the remaining group, count, slice\n",
    "    adp_parcel_linkages = address_gdf.groupby('link_field', dropna=True)['link_field'].count()\n",
    "    bf_parcel_linkages = footprint_gdf.groupby('link_field', dropna=True)['link_field'].count()\n",
    "\n",
    "    # Return only cases where the bf count is higher than the adp count\n",
    "    adp_parcel_l_bf = adp_parcel_linkages[adp_parcel_linkages.index.isin(bf_parcel_linkages.index.tolist())]\n",
    "    bf_parcel_l_ap = bf_parcel_linkages[bf_parcel_linkages.index.isin(adp_parcel_linkages.index.tolist())]\n",
    "\n",
    "    bf_parcel_l_ap = pd.DataFrame(bf_parcel_l_ap)\n",
    "    bf_parcel_l_ap.rename(columns={ bf_parcel_l_ap.columns[0]: \"bf_count\"}, inplace=True)\n",
    "\n",
    "    adp_parcel_l_bf = pd.DataFrame(adp_parcel_l_bf)\n",
    "    adp_parcel_l_bf.rename(columns={adp_parcel_l_bf.columns[0]: \"ap_count\"}, inplace=True)\n",
    "\n",
    "    linking_gdf = linking_gdf.loc[linking_gdf['link_field'].isin(bf_parcel_l_ap.index.tolist())]\n",
    "    linking_gdf['shed_list'] = linking_gdf['link_field'].apply(lambda x: find_sheds(footprint_gdf[footprint_gdf['link_field'] == x], adp_parcel_l_bf[adp_parcel_l_bf.index == x].ap_count.tolist()[0]))\n",
    "    shed_indexes = [ i for l in linking_gdf['shed_list'].tolist() for i in l ] # item for sublist in t for item in sublist: t being the shed_list list\n",
    "\n",
    "    shed_gdf = footprint_gdf[footprint_gdf['bf_index'].isin(shed_indexes)]\n",
    "    footprint_gdf = footprint_gdf.loc[~footprint_gdf['bf_index'].isin(shed_indexes)]\n",
    "\n",
    "    shed_gdf['shed_flag'] = True\n",
    "    round_sheds['shed_flag'] = True\n",
    "    footprint_gdf['shed_flag'] = False\n",
    "    footprint_gdf = footprint_gdf.append([shed_gdf, round_sheds])\n",
    "    return footprint_gdf\n",
    "\n",
    "footprint = shed_flagging(footprint, addresses, linking_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geo_env]",
   "language": "python",
   "name": "conda-env-geo_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
